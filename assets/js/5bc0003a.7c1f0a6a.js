"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[635],{29122:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>o,toc:()=>d});var n=i(74848),s=i(28453);const r={sidebar_position:2},a="System Block Diagram",o={id:"requirements/system-block-diagram",title:"System Block Diagram",description:"image",source:"@site/docs/requirements/system-block-diagram.md",sourceDirName:"requirements",slug:"/requirements/system-block-diagram",permalink:"/project-whiteboardflow/docs/requirements/system-block-diagram",draft:!1,unlisted:!1,editUrl:"https://github.com/capstone-projects-2024-fall/project-whiteboardflow/edit/main/documentation/docs/requirements/system-block-diagram.md",tags:[],version:"current",lastUpdatedBy:"Dhruvil patel",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"docsSidebar",previous:{title:"System Overview",permalink:"/project-whiteboardflow/docs/requirements/system-overview"},next:{title:"General Requirements",permalink:"/project-whiteboardflow/docs/requirements/general-requirements"}},c={},d=[{value:"Figure 1. High-level design of the Whiteboard Assistant application.",id:"figure-1-high-level-design-of-the-whiteboard-assistant-application",level:4}];function l(e){const t={h1:"h1",h4:"h4",img:"img",p:"p",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.h1,{id:"system-block-diagram",children:"System Block Diagram"}),"\n",(0,n.jsx)(t.p,{children:(0,n.jsx)(t.img,{src:"https://github.com/user-attachments/assets/73151275-1448-4686-a5cf-0b5bc72cdec3",alt:"image"})}),"\n",(0,n.jsx)(t.h4,{id:"figure-1-high-level-design-of-the-whiteboard-assistant-application",children:"Figure 1. High-level design of the Whiteboard Assistant application."}),"\n",(0,n.jsx)(t.p,{children:"Figure 1 provides an overview of the Whiteboard Assistant application architecture. Users interact with the system via mobile devices, using a stylus or touch input to simulate a whiteboard experience. The front-end, built with React (HTML5 and JavaScript), handles the user interface, enabling whiteboard drawing with the Canvas API or SVG. The backend, developed with FastAPI, manages API requests and real-time communication. AI/ML components, powered by openAI, process handwriting recognition, solution analysis, and natural language processing. Firebase securely stores user data, progress, and question banks, while user authentication is managed through Single Sign-On (SSO) with Google. Feedback and guidance are displayed on the user's device after completing the written and voice practice, enhancing the learning experience."})]})}function u(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(l,{...e})}):l(e)}},28453:(e,t,i)=>{i.d(t,{R:()=>a,x:()=>o});var n=i(96540);const s={},r=n.createContext(s);function a(e){const t=n.useContext(r);return n.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),n.createElement(r.Provider,{value:t},e.children)}}}]);